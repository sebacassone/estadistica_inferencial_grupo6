---
title: "EP07"
author: "Bastian Brito, Sebastian Cassone"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Enunciado
En el trabajo de título de una estudiante del DIINF se reportan tiempos de ejecución (en milisegundos) y la cercanía con la solución óptima (en por ciento) de la mejor solución encontrada con tres versiones de un algoritmo genético para resolver instancias del problema del vendedor viajero disponibles en repositorios públicos. Ahora debe enfrentar el análisis de estos datos, por que está solicitando ayuda de las y los estudiantes de Estadística Inferencial.


```{r}
# Importamos las librerías
library(dplyr)
library(tidyverse)
library(ggpubr)
library(ez)
library(emmeans)
library(nlme)
library(coin)

# Lectura de archivo
# Se abre el CSV
nombre_archivo <- "EP07 Datos.csv"
carpeta <- "~/Documentos/ejercicios_R/EI/estadistica_inferencial_grupo6/EP07"
ruta <- file.path(carpeta, nombre_archivo)
datos <- read.csv(ruta, sep = ",")
datos
```


# Pregunta
1. Observando los datos, la memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 60 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 60 o más nodos y seleccionen las columnas de los tiempos de ejecución de las versiones A y C en formato ancho. Usando como semilla el valor 33, obtenga muestras aleatorias independientes de 24 tiempos registrados por la versión A y 18 tiempos registrados por la versión C del algoritmo. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

```{r}
# Fijamos la semilla
set.seed(33)

# Filtramos los datos por instancias con 60 nodos
datos_60Nodos1 <- datos %>%
  filter(n.nodos >= 60)

# Se deja solo las mediciones de el algoritmo A y C

datos_filtrados1 <- datos_60Nodos1 %>%
  select(-tiempo.B, -mejor.B)

# Sacamos los 24 tiempo random para A
muestras_A <- datos_filtrados1 %>%
  select(tiempo.A) %>%
  sample_n(24)

# Sacamos los 18 tiempo random para C
muestras_C <- datos_filtrados1 %>%
  select(tiempo.C) %>%
  sample_n(18)
```

Primero probaremos la normalidad de los datos con Shapiro-Wilk.

```{r}
# Comprobamos la normalidad de los datos con el test de Shapiro
shapiro_A <- shapiro.test(muestras_A$tiempo.A)
shapiro_C <- shapiro.test(muestras_C$tiempo.C)
shapiro_A
shapiro_C
```

Como el valor p de la prueba Shapiro-Wilk en las muestras de A es menor que nuestro nivel de significancia (alfa = 0.05), podemos concluir que las observaciones no siguen una distribución normal.

Como no siguen una distribución normal y los datos son muestras independientes, se usara la prueba no paramétrica "Prueba de Sumas de Rangos de Wilcoxon", ya que no se puede usar la prueba t student ni la prueba z debido falta de normalidad.

Las condiciones para la prueba de rangos de Wilcoxon son:
 - 1. Los pares de observaciones son independientes
 - 2. La escala de medicón empleada para ambas muestras debe ser a lo menos ordinal

La condición 1 se cumple porque cada instancia no depende de la otra, la condición 2 se cumple ya que los datos son cuantitativos y continuos.

Ho: No hay diferencia en el tiempo de los algoritmos con respecto la mediana de los tiempos de ejecución entre las versiones A y C del algoritmo, para instancias con 60 o más nodos.

Ha: Existe una diferencia en la mediana de los tiempos de ejecución entre las versiones A y C del algoritmo para instancias con 60 o más nodos.


```{r}
alfa <- 0.05

# Aplicamo la prueba de wilcoxon
prueba1 <- wilcox.test(muestras_A$tiempo.A, muestras_C$tiempo.C, alternative = "two.sided", conf.level = 1 - alfa)

print(prueba1)
```

Como nuestro p-value = 0.9299 y este es mayor que la significancia considerada para este experimento de 0.05, no se puede rechazar la hipótesis nula que no hay diferencia en el tiempo de los algoritmos con respecto la mediana de los tiempos de ejecución entre las versiones A y C del algoritmo para instancias con 60 o más nodos.

2. La memorista también sospecha que, al comparar las mismas instancias de iguales características, las mejores soluciones encontradas por las versiones A y B tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias con 60 o más nodos y seleccionen las columnas con el mejor rendimiento de las versiones A y B en formato ancho. Usando como semilla el valor 33, obtengan una muestra aleatoria de 22 instancias. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

Como son muestras apareadas, usaremos la prueba de rangos con signo de Wilcoxon, las condiciones para esta prueba son:

1. Los pares de observaciones son independientes.
2. La escala de medición empleada para las observaciones es intrínsecamente continua.
3. La escala de mediciones empleada para ambas muestras debe ser a lo menos ordinal.

```{r}
# Fijamos la semilla
set.seed(33)


# Filtramos los datos por instancias con 60 nodos
datos_60Nodos2 <- datos %>%
  filter(n.nodos >= 60)

# Se deja solo las mediciones de el algoritmo A y B
datos_filtrados2 <- datos_60Nodos2 %>%
  select(-tiempo.A, -tiempo.B, -tiempo.C, -mejor.C)

datos_aleatorios2 <- sample_n(datos_filtrados2, 22)
```

Primero probaremos la normalidad de los datos con Shapiro-Wilk.

```{r}
# Comprobamos la normalidad de los datos con el test de Shapiro

# Restamos los porcentajes de los mejore de a menos los mejores de B
A_less_B <- datos_aleatorios2$mejor.A - datos_aleatorios2$mejor.B

# Aplicamos Shapiro a la diferencia de los porcentajes
shapiro_2 <- shapiro.test(A_less_B)
shapiro_2
```

Como nuestro el p-value de la prueba Shapiro-Wilk en las muestras de A es menor a nuestro nivel de significancia (alfa = 0.05), podemos decir que las observaciones no siguen una distribución normal.

Como no siguen una distribución normal y los datos son muestras independientes, se usara la prueba no paramétrica "prueba de rangos con signo de Wilcoxon", ya que no se puede usar la prueba t studenen ni la z y los datos son correlacionados. Las condiciones para esta prueba son:

1. Los pares de observaciones son independientes.
2. La escala de medición empleada para las observaciones es intrínsecamente continua.
3. La escala de mediciones empleada para ambas muestras debe ser a lo menos ordinal.

Los pares de observaciones son elegidos aleatoriamente, por lo que se cumple la condición 1, la escala de medición empleada en las observaciones es el tiempo, por lo que la hace una escala continua y mejor que ordinal, ya que los datos son cuantitativos, cumpliendose las condiciones 2 y 3 respectivamente.

Ho: Las mejores soluciones encontradas por las versiones A y B tienen rendimientos iguales.
Ha: Las mejores soluciones encontradas por las versiones A y B tienen rendimientos distintos.

Procedemos a usar la prueba de rangos con signos.

```{r}
alfa <- 0.05

# Aplicamos la prueba de wilcox con datos pareados
prueba2 <- wilcox.test(datos_aleatorios2$mejor.A, datos_aleatorios2$mejor.B, alternative = "two.sided", paired = TRUE, conf.level = 1 - alfa)
prueba2
```

Como nuestro p-value es menor a nuestro nivel de significancia (alfa = 0.05), podemos decir con un 95% de certeza, que se rechaza la hipotesis nula a favor de la hipotesis alternativa, entonces, podemos decir que al comparar las mismas instancias de iguales características, las mejores soluciones encontradas por las versiones A y B tienen rendimientos distintos. 

3- La memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 45 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 45 o más nodos y seleccionen las columnas con los tiempos de ejecución registrados (en formato ancho). Usando como semilla el valor 43, obtengan muestras aleatorias independientes de 15, 15 y 14 tiempos registrados por las versiones A, B y C, respectivamente. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

```{r}
# Fijamos la semilla
set.seed(43)

# Filtramos los datos por instancias con 60 nodos
datos_45Nodos3 <- datos %>%
  filter(n.nodos >= 45)

# Se deja solo las mediciones de el algoritmo A y B

datos_filtrados3 <- datos_45Nodos3 %>%
  select(-mejor.A, -mejor.B, -mejor.C)


# Sacamos los 15 tiempo random para A
muestras_3.A <- datos_filtrados1 %>%
  select(tiempo.A) %>%
  sample_n(15)

# Sacamos los 15 tiempo random para B
muestras_3.B <- datos_filtrados3 %>%
  select(tiempo.B) %>%
  sample_n(15)

# Sacamos los 14 tiempo random para C
muestras_3.C <- datos_filtrados3 %>%
  select(tiempo.C) %>%
  sample_n(15)
```

Primero, probaremos la normalidad de los datos con el test de Shapiro-Wilk.

```{r}
# Comprobamos la normalidad de los datos con el test de Shapiro
shapiro_3.A <- shapiro.test(muestras_3.A$tiempo.A)
shapiro_3.B <- shapiro.test(muestras_3.B$tiempo.B)
shapiro_3.C <- shapiro.test(muestras_3.C$tiempo.C)
shapiro_3.A
shapiro_3.B
shapiro_3.C
```

Como el p-value de los tiempos de A, es menor a nuestro nivel de significancia (alfa = 0.05), los datos ya no siguen una distribución normal, por lo que tendremos que usar una prueba no parametrica.

Como son más de 2 muestras y los datos son independiente, usaremos Kruskal-Wallis.

Las condiciones de esta prueba son:

  1. La variable independiente debe tener a lo menos dos niveles.
  2. La escala de la variable dependiente debe ser, a lo menos ordinal.
  3. Las observacones son indepenientes entre sí.
  
- La condición 1 es cumple ya que, son 3 instancias (A,B o C), por lo que serian 3 niveles.
- La condición 2 se cumple ya que la variable dependiente es el tiempo, y como es continuo la hace mejor que ordinal.
-La condición 3 se cumple ya que las muestras se eligen de forma aleatoria y entre par de observaciones son independientes.

Ho: No hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 45 o más nodos.

Ha: Hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 45 o más nodos.

```{r}
# Establecemos un nivel de significancia
alfa <- 0.05

d.f3 <- data.frame(muestras_3.A, muestras_3.B, muestras_3.C)

datos3 <- d.f3 %>% pivot_longer(c("tiempo.A", "tiempo.B", "tiempo.C"),
  names_to = "Algoritmo", values_to = "Tiempo"
)

# Usamos la prueba de Kruskal-Wallis
prueba3 <- kruskal.test(Tiempo ~ Algoritmo, data = datos3)
prueba3
```

Como nuestro p.value es menor a nuestro nivel de significancia (alfa = 0.05), podemos decir con un 95% de certeza, que se rechaza la hipotesis nula a favor de la hipotesis alternativa, entonces, podemos decir que hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 45 o más nodos.

Ahora hacemos el procedimiento post-hoc, para saber cúal es el algoritmo que tiene tiempo diferentes.

```{r}
# Hacemos el post-hoc
post_hoc3 <- pairwise.wilcox.test(datos3$Tiempo, datos3$Algoritmo,
  p.adjust.method = "holm",
  paired = FALSE
)
post_hoc3
```

Como se puede ver en el procedimiento post-hoc, podemos concluir con un 95% de confianza que existen diferencias significativas entre los tiempos de ejecución de todos los pares de algoritmos excepto los algoritmos A y C.


4.- La memorista también sospecha que, al comparar las mismas instancias con iguales características, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias con 45 o más nodos y seleccionen las columnas con los mejores rendimientos registrados. Usando como semilla el valor 71, obtengan una muestra aleatoria de 23 instancias. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

```{r}
# Fijamos la semilla
set.seed(71)

# Filtramos los datos por instancias con 60 nodos
datos_45Nodos4 <- datos %>%
  filter(n.nodos >= 45)

# Se deja solo las mediciones de el algoritmo A y B

datos_filtrados4 <- datos_45Nodos4 %>%
  select(-tiempo.A, -tiempo.B, -tiempo.C)

datos_aleatorios4 <- sample_n(datos_filtrados4, 23)

```

Primero revisamos la normalidad de los datos con Shapiro-Wilk.

```{r}
#Proabmos normalidad de los datos, en la resta de cada par de muestras
A_less_B_less_C <- datos_aleatorios4$mejor.A - datos_aleatorios4$mejor.B - datos_aleatorios4$mejor.C


shapiro_4 <- shapiro.test(A_less_B_less_C)
shapiro_4

```

Como se ve en las pruebas, el p-values es menor a nuestro nivel de significancia (alfa=0,05), por lo tanto los datos no siguen una distribución normal. 

Como no sigue una distribución normal, consideraremos alguna prueba paramétrica, como son más de 2 muestras y los datos estan correlacionados, usaremos la prueba de Frideman.

Las condiciones de esta prueba son:

  1.- La variable independiente debe ser categórica y tener al menos tres niveles.
  2.- La escala de la variable dependiente debe ser, a lo menos, ordinal.
  3.- Las observaciones son una muestra aleatoria e independiente de la población.
  
- La condición 1 es cumple ya que, son 3 instancias (A,B o C), por lo que serian 3 niveles.
- La condición 2 se cumple ya que la variable dependiente es el tiempo, y como es continuo la hace mejor que ordinal.
- La condición 3 se cumple ya que las muestras se eligen de forma aleatoria y entre par de observaciones son independientes.

Ho: Al comparar las mismas instancias con iguales características, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos iguales.
Ha: Al comparar las mismas instancias con iguales características, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos.


```{r}
#Fijamos un nivel de significancia
alfa <- 0.05

#Dejamos todo en una sola columna
datos4 <- datos_aleatorios4%>% pivot_longer(c("mejor.A", "mejor.B", "mejor.C"),
  names_to = "Algoritmo", values_to = "Tiempo")

#Usamos la prueba de Frideman
prueba4 <- friedman.test(Tiempo ~ Algoritmo|instancia, data = datos4)
prueba4
```

Como nuestro p-value es menor al nivel de significancia, podemos decir con un 95% de confianza, que se rechaza la hipotesis nula, a favor de la hipotesis alternativa, osea, al comparar las mismas instancias con iguales características, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos.

Procederemos a usar un procedimiento post-hoc.

```{r}
post_hoc4 <- pairwise.wilcox.test(datos4$Tiempo,
                                  datos4$Algoritmo,
                                  p.adjust.method = "holm",
                                  paired = TRUE)
post_hoc4

```

Como se puede ver en el procedimiento post-hoc, podemos concluir con un nivel de confianza del 95% que existen diferencias significativas entre los tiempos de ejecución de todos los pares de algoritmos, excepto entre los algoritmos B y C.
